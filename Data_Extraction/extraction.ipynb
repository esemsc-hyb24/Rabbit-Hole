{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba55785a",
   "metadata": {},
   "source": [
    "## Safari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "history_db = os.path.expanduser(\"~/Library/Safari/HistoryCopy.db\")\n",
    "history_db = \"HistoryCopy.db\"\n",
    "conn = sqlite3.connect(history_db)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT datetime(visit_time + 978307200, 'unixepoch') as visit_date, url, title\n",
    "FROM history_visits\n",
    "INNER JOIN history_items ON history_items.id = history_visits.history_item\n",
    "ORDER BY visit_date DESC\n",
    "\"\"\"\n",
    "\n",
    "for row in cursor.execute(query):\n",
    "    print(row)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce1aef",
   "metadata": {},
   "source": [
    "## Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac19622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "db_path = \"places.sqlite\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# Connect to the copied database\n",
    "# conn = sqlite3.connect()\n",
    "\n",
    "# SQL query to extract visit time, url, and title\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    datetime(moz_historyvisits.visit_date/1000000, 'unixepoch') as visit_time,\n",
    "    moz_places.url,\n",
    "    moz_places.title\n",
    "FROM moz_places\n",
    "JOIN moz_historyvisits\n",
    "ON moz_places.id = moz_historyvisits.place_id\n",
    "ORDER BY visit_time DESC\n",
    "\"\"\"\n",
    "\n",
    "# Load into pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Optional: Preview the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Filenames\n",
    "output_file = \"firefox_history_with_text.csv\"\n",
    "\n",
    "# Load previous progress if exists\n",
    "if os.path.exists(output_file):\n",
    "    df = pd.read_csv(output_file)\n",
    "    print(f\"Resuming from existing file: {output_file}\")\n",
    "else:\n",
    "\n",
    "    df['page_text'] = None\n",
    "# df['page_text'] = None\n",
    "# Set up headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Iterate and resume based on page_text column\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Skip if already processed\n",
    "    if pd.notna(row['page_text']):\n",
    "        continue\n",
    "    \n",
    "    title = str(row['title'])\n",
    "    url = row['url']\n",
    "    # print(title)\n",
    "    # Skip Google Search result pages\n",
    "    if title is not None and title.strip().endswith(\"- Google Search\"):\n",
    "        df.at[i, 'page_text'] = title\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        df.at[i, 'page_text'] = text[:5000]  # Truncate long text\n",
    "    except Exception as e:\n",
    "        df.at[i, 'page_text'] = f\"[ERROR] {str(e)}\"\n",
    "\n",
    "    # Save progress after each row\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Done\n",
    "print(\"Scraping complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
